{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataset import CWRUDataset\n",
    "from models import WDCNN\n",
    "from configs import window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset..\n",
      "datasets from 29 file(s) loaded.\n"
     ]
    }
   ],
   "source": [
    "exp_list = ['12DriveEndFault']\n",
    "rpm_list = ['1772', '1750', '1730']\n",
    "\n",
    "dataset = CWRUDataset(exp_list, rpm_list, window_size)\n",
    "\n",
    "model = WDCNN()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to('cuda')\n",
    "else:\n",
    "    model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.6 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import wdcnn_trainer\n",
    "from configs import batch_size, learning_rate, n_iter\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = wdcnn_trainer(model, train_dataset, val_dataset, batch_size, learning_rate, n_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1500], Training Loss: 2.2493, Validation Loss: 2.1900, Validation Accuracy: 30.65%\n",
      "Validation loss decreased from inf to 2.1900. Saving model...\n",
      "Epoch [11/1500], Training Loss: 1.9170, Validation Loss: 1.8917, Validation Accuracy: 64.13%\n",
      "Validation loss decreased from 1.9257 to 1.8917. Saving model...\n",
      "Epoch [21/1500], Training Loss: 1.7810, Validation Loss: 1.7809, Validation Accuracy: 71.52%\n",
      "Validation loss decreased from 1.7839 to 1.7809. Saving model...\n",
      "Epoch [31/1500], Training Loss: 1.7418, Validation Loss: 1.7188, Validation Accuracy: 73.70%\n",
      "Validation loss decreased from 1.7246 to 1.7188. Saving model...\n",
      "Epoch [41/1500], Training Loss: 1.6968, Validation Loss: 1.6815, Validation Accuracy: 80.87%\n",
      "Epoch [51/1500], Training Loss: 1.6772, Validation Loss: 1.7580, Validation Accuracy: 70.00%\n",
      "Epoch [61/1500], Training Loss: 1.6580, Validation Loss: 1.6398, Validation Accuracy: 86.30%\n",
      "Validation loss decreased from 1.6438 to 1.6398. Saving model...\n",
      "Epoch [71/1500], Training Loss: 1.6431, Validation Loss: 1.6199, Validation Accuracy: 89.35%\n",
      "Validation loss decreased from 1.6270 to 1.6199. Saving model...\n",
      "Epoch [81/1500], Training Loss: 1.6536, Validation Loss: 1.6011, Validation Accuracy: 89.35%\n",
      "Epoch [91/1500], Training Loss: 1.6256, Validation Loss: 1.6075, Validation Accuracy: 89.13%\n",
      "Epoch [101/1500], Training Loss: 1.6184, Validation Loss: 1.5906, Validation Accuracy: 89.78%\n",
      "Epoch [111/1500], Training Loss: 1.6159, Validation Loss: 1.5863, Validation Accuracy: 90.00%\n",
      "Epoch [121/1500], Training Loss: 1.6214, Validation Loss: 1.6030, Validation Accuracy: 90.00%\n",
      "Epoch [131/1500], Training Loss: 1.6108, Validation Loss: 1.5961, Validation Accuracy: 89.35%\n",
      "Epoch [141/1500], Training Loss: 1.6113, Validation Loss: 1.5927, Validation Accuracy: 90.00%\n",
      "Epoch [151/1500], Training Loss: 1.6053, Validation Loss: 1.5788, Validation Accuracy: 90.22%\n",
      "Epoch [161/1500], Training Loss: 1.6021, Validation Loss: 1.5674, Validation Accuracy: 90.22%\n",
      "Validation loss decreased from 1.5676 to 1.5674. Saving model...\n",
      "Epoch [171/1500], Training Loss: 1.6059, Validation Loss: 1.5639, Validation Accuracy: 90.43%\n",
      "Validation loss decreased from 1.5652 to 1.5639. Saving model...\n",
      "Epoch [181/1500], Training Loss: 1.6050, Validation Loss: 1.5784, Validation Accuracy: 90.43%\n",
      "Epoch [191/1500], Training Loss: 1.6007, Validation Loss: 1.5688, Validation Accuracy: 90.43%\n",
      "Epoch [201/1500], Training Loss: 1.6075, Validation Loss: 1.5755, Validation Accuracy: 90.43%\n",
      "Epoch [211/1500], Training Loss: 1.5992, Validation Loss: 1.5799, Validation Accuracy: 89.57%\n",
      "Epoch [221/1500], Training Loss: 1.6081, Validation Loss: 1.5671, Validation Accuracy: 90.65%\n",
      "Epoch [231/1500], Training Loss: 1.6051, Validation Loss: 1.5865, Validation Accuracy: 88.26%\n",
      "Epoch [241/1500], Training Loss: 1.6032, Validation Loss: 1.5577, Validation Accuracy: 90.43%\n",
      "Epoch [251/1500], Training Loss: 1.6031, Validation Loss: 1.5749, Validation Accuracy: 90.43%\n",
      "Epoch [261/1500], Training Loss: 1.5976, Validation Loss: 1.5644, Validation Accuracy: 89.35%\n",
      "Epoch [271/1500], Training Loss: 1.5997, Validation Loss: 1.5567, Validation Accuracy: 90.22%\n",
      "Epoch [281/1500], Training Loss: 1.6040, Validation Loss: 1.5509, Validation Accuracy: 90.87%\n",
      "Validation loss decreased from 1.5523 to 1.5509. Saving model...\n",
      "Epoch [291/1500], Training Loss: 1.5968, Validation Loss: 1.5523, Validation Accuracy: 90.43%\n",
      "Epoch [301/1500], Training Loss: 1.5732, Validation Loss: 1.5568, Validation Accuracy: 94.78%\n",
      "Epoch [311/1500], Training Loss: 1.5778, Validation Loss: 1.5392, Validation Accuracy: 97.17%\n",
      "Epoch [321/1500], Training Loss: 1.5601, Validation Loss: 1.5159, Validation Accuracy: 97.17%\n",
      "Validation loss decreased from 1.5259 to 1.5159. Saving model...\n",
      "Epoch [331/1500], Training Loss: 1.5472, Validation Loss: 1.5158, Validation Accuracy: 97.39%\n",
      "Epoch [341/1500], Training Loss: 1.5443, Validation Loss: 1.5023, Validation Accuracy: 97.61%\n",
      "Validation loss decreased from 1.5055 to 1.5023. Saving model...\n",
      "Epoch [351/1500], Training Loss: 1.5373, Validation Loss: 1.5393, Validation Accuracy: 94.78%\n",
      "Epoch [361/1500], Training Loss: 1.5222, Validation Loss: 1.4976, Validation Accuracy: 97.39%\n",
      "Epoch [371/1500], Training Loss: 1.5305, Validation Loss: 1.4943, Validation Accuracy: 97.39%\n",
      "Epoch [381/1500], Training Loss: 1.5358, Validation Loss: 1.4967, Validation Accuracy: 96.96%\n",
      "Epoch [391/1500], Training Loss: 1.5406, Validation Loss: 1.5002, Validation Accuracy: 97.17%\n",
      "Epoch [401/1500], Training Loss: 1.5206, Validation Loss: 1.4970, Validation Accuracy: 96.96%\n",
      "Epoch [411/1500], Training Loss: 1.5325, Validation Loss: 1.4910, Validation Accuracy: 97.39%\n",
      "Epoch [421/1500], Training Loss: 1.5197, Validation Loss: 1.4908, Validation Accuracy: 97.17%\n",
      "Epoch [431/1500], Training Loss: 1.5142, Validation Loss: 1.4853, Validation Accuracy: 97.83%\n",
      "Validation loss decreased from 1.4854 to 1.4853. Saving model...\n",
      "Epoch [441/1500], Training Loss: 1.5109, Validation Loss: 1.4989, Validation Accuracy: 97.17%\n",
      "Epoch [451/1500], Training Loss: 1.5066, Validation Loss: 1.4901, Validation Accuracy: 97.39%\n",
      "Epoch [461/1500], Training Loss: 1.5127, Validation Loss: 1.4889, Validation Accuracy: 97.39%\n",
      "Epoch [471/1500], Training Loss: 1.5168, Validation Loss: 1.4925, Validation Accuracy: 97.17%\n",
      "Epoch [481/1500], Training Loss: 1.5142, Validation Loss: 1.4885, Validation Accuracy: 97.17%\n",
      "Epoch [491/1500], Training Loss: 1.5007, Validation Loss: 1.4835, Validation Accuracy: 97.83%\n",
      "Epoch [501/1500], Training Loss: 1.5069, Validation Loss: 1.4846, Validation Accuracy: 97.83%\n",
      "Epoch [511/1500], Training Loss: 1.5122, Validation Loss: 1.4876, Validation Accuracy: 97.17%\n",
      "Epoch [521/1500], Training Loss: 1.5037, Validation Loss: 1.4913, Validation Accuracy: 96.74%\n",
      "Epoch [531/1500], Training Loss: 1.5116, Validation Loss: 1.4833, Validation Accuracy: 97.83%\n",
      "Epoch [541/1500], Training Loss: 1.5084, Validation Loss: 1.5053, Validation Accuracy: 96.96%\n",
      "Epoch [551/1500], Training Loss: 1.5121, Validation Loss: 1.4896, Validation Accuracy: 96.74%\n",
      "Epoch [561/1500], Training Loss: 1.5097, Validation Loss: 1.4862, Validation Accuracy: 97.39%\n",
      "Epoch [571/1500], Training Loss: 1.4989, Validation Loss: 1.4930, Validation Accuracy: 97.61%\n",
      "Epoch [581/1500], Training Loss: 1.5056, Validation Loss: 1.5232, Validation Accuracy: 93.91%\n",
      "Epoch [591/1500], Training Loss: 1.5071, Validation Loss: 1.4888, Validation Accuracy: 98.04%\n",
      "Epoch [601/1500], Training Loss: 1.5072, Validation Loss: 1.4801, Validation Accuracy: 98.04%\n",
      "Epoch [611/1500], Training Loss: 1.4993, Validation Loss: 1.4805, Validation Accuracy: 97.83%\n",
      "Epoch [621/1500], Training Loss: 1.5033, Validation Loss: 1.4883, Validation Accuracy: 97.17%\n",
      "Epoch [631/1500], Training Loss: 1.4979, Validation Loss: 1.4841, Validation Accuracy: 97.61%\n",
      "Epoch [641/1500], Training Loss: 1.5041, Validation Loss: 1.4817, Validation Accuracy: 97.83%\n",
      "Epoch [651/1500], Training Loss: 1.5042, Validation Loss: 1.4878, Validation Accuracy: 97.39%\n",
      "Epoch [661/1500], Training Loss: 1.4942, Validation Loss: 1.4786, Validation Accuracy: 98.26%\n",
      "Validation loss decreased from 1.4795 to 1.4786. Saving model...\n",
      "Epoch [671/1500], Training Loss: 1.4901, Validation Loss: 1.4815, Validation Accuracy: 97.83%\n",
      "Epoch [681/1500], Training Loss: 1.4993, Validation Loss: 1.4877, Validation Accuracy: 97.61%\n",
      "Epoch [691/1500], Training Loss: 1.5006, Validation Loss: 1.4894, Validation Accuracy: 97.83%\n",
      "Epoch [701/1500], Training Loss: 1.4916, Validation Loss: 1.4793, Validation Accuracy: 98.04%\n",
      "Epoch [711/1500], Training Loss: 1.5011, Validation Loss: 1.4818, Validation Accuracy: 97.83%\n",
      "Epoch [721/1500], Training Loss: 1.5447, Validation Loss: 1.5557, Validation Accuracy: 90.43%\n",
      "Epoch [731/1500], Training Loss: 1.4968, Validation Loss: 1.4916, Validation Accuracy: 96.74%\n",
      "Epoch [741/1500], Training Loss: 1.4915, Validation Loss: 1.4888, Validation Accuracy: 97.83%\n",
      "Epoch [751/1500], Training Loss: 1.4983, Validation Loss: 1.4898, Validation Accuracy: 97.83%\n",
      "Epoch [761/1500], Training Loss: 1.5006, Validation Loss: 1.4799, Validation Accuracy: 98.04%\n",
      "Epoch [771/1500], Training Loss: 1.4954, Validation Loss: 1.4812, Validation Accuracy: 97.83%\n",
      "Epoch [781/1500], Training Loss: 1.4950, Validation Loss: 1.4794, Validation Accuracy: 98.04%\n",
      "Epoch [791/1500], Training Loss: 1.4960, Validation Loss: 1.5230, Validation Accuracy: 93.04%\n",
      "Epoch [801/1500], Training Loss: 1.4990, Validation Loss: 1.5033, Validation Accuracy: 95.43%\n",
      "Epoch [811/1500], Training Loss: 1.5007, Validation Loss: 1.4976, Validation Accuracy: 97.83%\n",
      "Epoch [821/1500], Training Loss: 1.4993, Validation Loss: 1.4792, Validation Accuracy: 98.04%\n",
      "Epoch [831/1500], Training Loss: 1.4938, Validation Loss: 1.4799, Validation Accuracy: 98.04%\n",
      "Epoch [841/1500], Training Loss: 1.4945, Validation Loss: 1.4790, Validation Accuracy: 98.04%\n",
      "Epoch [851/1500], Training Loss: 1.4998, Validation Loss: 1.4801, Validation Accuracy: 97.83%\n",
      "Epoch [861/1500], Training Loss: 1.4906, Validation Loss: 1.4889, Validation Accuracy: 97.17%\n",
      "Epoch [871/1500], Training Loss: 1.4921, Validation Loss: 1.4788, Validation Accuracy: 98.04%\n",
      "Epoch [881/1500], Training Loss: 1.5025, Validation Loss: 1.5041, Validation Accuracy: 95.22%\n",
      "Epoch [891/1500], Training Loss: 1.5382, Validation Loss: 1.5142, Validation Accuracy: 96.09%\n",
      "Epoch [901/1500], Training Loss: 1.4975, Validation Loss: 1.4791, Validation Accuracy: 98.04%\n",
      "Epoch [911/1500], Training Loss: 1.4981, Validation Loss: 1.4769, Validation Accuracy: 98.26%\n",
      "Epoch [921/1500], Training Loss: 1.5209, Validation Loss: 1.5082, Validation Accuracy: 96.74%\n",
      "Epoch [931/1500], Training Loss: 1.5000, Validation Loss: 1.4823, Validation Accuracy: 97.83%\n",
      "Epoch [941/1500], Training Loss: 1.4884, Validation Loss: 1.4866, Validation Accuracy: 98.04%\n",
      "Epoch [951/1500], Training Loss: 1.4949, Validation Loss: 1.4825, Validation Accuracy: 97.61%\n",
      "Epoch [961/1500], Training Loss: 1.4985, Validation Loss: 1.4874, Validation Accuracy: 98.04%\n",
      "Epoch [971/1500], Training Loss: 1.4965, Validation Loss: 1.4891, Validation Accuracy: 97.83%\n",
      "Epoch [981/1500], Training Loss: 1.4974, Validation Loss: 1.4798, Validation Accuracy: 98.04%\n",
      "Epoch [991/1500], Training Loss: 1.4974, Validation Loss: 1.4789, Validation Accuracy: 98.04%\n",
      "Epoch [1001/1500], Training Loss: 1.4872, Validation Loss: 1.4821, Validation Accuracy: 97.61%\n",
      "Epoch [1011/1500], Training Loss: 1.4899, Validation Loss: 1.4759, Validation Accuracy: 98.48%\n",
      "Epoch [1021/1500], Training Loss: 1.4998, Validation Loss: 1.4851, Validation Accuracy: 98.26%\n",
      "Epoch [1031/1500], Training Loss: 1.4897, Validation Loss: 1.4765, Validation Accuracy: 98.26%\n",
      "Epoch [1041/1500], Training Loss: 1.5027, Validation Loss: 1.4777, Validation Accuracy: 98.26%\n",
      "Epoch [1051/1500], Training Loss: 1.5099, Validation Loss: 1.6139, Validation Accuracy: 84.78%\n",
      "Epoch [1061/1500], Training Loss: 1.4970, Validation Loss: 1.4794, Validation Accuracy: 98.04%\n",
      "Epoch [1071/1500], Training Loss: 1.4862, Validation Loss: 1.4788, Validation Accuracy: 98.04%\n",
      "Epoch [1081/1500], Training Loss: 1.4907, Validation Loss: 1.4794, Validation Accuracy: 98.04%\n",
      "Epoch [1091/1500], Training Loss: 1.4956, Validation Loss: 1.4847, Validation Accuracy: 97.39%\n",
      "Epoch [1101/1500], Training Loss: 1.5003, Validation Loss: 1.4871, Validation Accuracy: 98.04%\n",
      "Epoch [1111/1500], Training Loss: 1.5039, Validation Loss: 1.4815, Validation Accuracy: 97.83%\n",
      "Epoch [1121/1500], Training Loss: 1.4911, Validation Loss: 1.4865, Validation Accuracy: 97.39%\n",
      "Epoch [1131/1500], Training Loss: 1.4957, Validation Loss: 1.4816, Validation Accuracy: 97.61%\n",
      "Epoch [1141/1500], Training Loss: 1.4978, Validation Loss: 1.4875, Validation Accuracy: 98.04%\n",
      "Epoch [1151/1500], Training Loss: 1.4987, Validation Loss: 1.4769, Validation Accuracy: 98.26%\n",
      "Epoch [1161/1500], Training Loss: 1.4984, Validation Loss: 1.4810, Validation Accuracy: 97.83%\n",
      "Epoch [1171/1500], Training Loss: 1.4889, Validation Loss: 1.4824, Validation Accuracy: 97.39%\n",
      "Epoch [1181/1500], Training Loss: 1.4935, Validation Loss: 1.4788, Validation Accuracy: 98.04%\n",
      "Epoch [1191/1500], Training Loss: 1.4927, Validation Loss: 1.4782, Validation Accuracy: 98.04%\n",
      "Epoch [1201/1500], Training Loss: 1.4935, Validation Loss: 1.4806, Validation Accuracy: 97.83%\n",
      "Epoch [1211/1500], Training Loss: 1.4915, Validation Loss: 1.4789, Validation Accuracy: 98.04%\n",
      "Epoch [1221/1500], Training Loss: 1.4986, Validation Loss: 1.4799, Validation Accuracy: 98.04%\n",
      "Epoch [1231/1500], Training Loss: 1.4976, Validation Loss: 1.4871, Validation Accuracy: 97.17%\n",
      "Epoch [1241/1500], Training Loss: 1.5035, Validation Loss: 1.5025, Validation Accuracy: 95.43%\n",
      "Epoch [1251/1500], Training Loss: 1.4938, Validation Loss: 1.4831, Validation Accuracy: 97.61%\n",
      "Epoch [1261/1500], Training Loss: 1.4888, Validation Loss: 1.4849, Validation Accuracy: 98.26%\n",
      "Epoch [1271/1500], Training Loss: 1.4953, Validation Loss: 1.4766, Validation Accuracy: 98.26%\n",
      "Epoch [1281/1500], Training Loss: 1.4913, Validation Loss: 1.4767, Validation Accuracy: 98.26%\n",
      "Epoch [1291/1500], Training Loss: 1.4919, Validation Loss: 1.4755, Validation Accuracy: 98.48%\n",
      "Epoch [1301/1500], Training Loss: 1.5050, Validation Loss: 1.4736, Validation Accuracy: 98.70%\n",
      "Epoch [1311/1500], Training Loss: 1.5093, Validation Loss: 1.5742, Validation Accuracy: 90.43%\n",
      "Epoch [1321/1500], Training Loss: 1.4955, Validation Loss: 1.4768, Validation Accuracy: 98.26%\n",
      "Epoch [1331/1500], Training Loss: 1.4910, Validation Loss: 1.4869, Validation Accuracy: 98.04%\n",
      "Epoch [1341/1500], Training Loss: 1.4930, Validation Loss: 1.4796, Validation Accuracy: 97.83%\n",
      "Epoch [1351/1500], Training Loss: 1.4921, Validation Loss: 1.4790, Validation Accuracy: 98.04%\n",
      "Epoch [1361/1500], Training Loss: 1.4913, Validation Loss: 1.4818, Validation Accuracy: 97.61%\n",
      "Epoch [1371/1500], Training Loss: 1.4955, Validation Loss: 1.4818, Validation Accuracy: 97.61%\n",
      "Epoch [1381/1500], Training Loss: 1.4943, Validation Loss: 1.4835, Validation Accuracy: 97.61%\n",
      "Epoch [1391/1500], Training Loss: 1.5101, Validation Loss: 1.4943, Validation Accuracy: 96.30%\n",
      "Epoch [1401/1500], Training Loss: 1.4898, Validation Loss: 1.4807, Validation Accuracy: 97.83%\n",
      "Epoch [1411/1500], Training Loss: 1.4855, Validation Loss: 1.4814, Validation Accuracy: 97.83%\n",
      "Epoch [1421/1500], Training Loss: 1.4919, Validation Loss: 1.4829, Validation Accuracy: 97.61%\n",
      "Epoch [1431/1500], Training Loss: 1.4965, Validation Loss: 1.4773, Validation Accuracy: 98.26%\n",
      "Epoch [1441/1500], Training Loss: 1.4936, Validation Loss: 1.4773, Validation Accuracy: 98.26%\n",
      "Epoch [1451/1500], Training Loss: 1.4882, Validation Loss: 1.4840, Validation Accuracy: 97.61%\n",
      "Epoch [1461/1500], Training Loss: 1.4936, Validation Loss: 1.4818, Validation Accuracy: 97.83%\n",
      "Epoch [1471/1500], Training Loss: 1.5051, Validation Loss: 1.4865, Validation Accuracy: 97.17%\n",
      "Epoch [1481/1500], Training Loss: 1.4947, Validation Loss: 1.4817, Validation Accuracy: 97.61%\n",
      "Epoch [1491/1500], Training Loss: 1.4942, Validation Loss: 1.4904, Validation Accuracy: 97.61%\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
